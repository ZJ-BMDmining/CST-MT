{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset,TensorDataset,SubsetRandomSampler\n",
    "from sklearn.metrics import classification_report\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_recall_curve,f1_score,roc_curve,roc_auc_score,auc,accuracy_score,average_precision_score,precision_score,recall_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        # torch.cuda.manual_seed_all(seed)  # 如果使用多个GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_img(t_img):\n",
    "    img = pd.read_pickle(t_img)\n",
    "    img_l = []\n",
    "    for i in range(len(img)):\n",
    "        img_l.append(img.values[i][0])\n",
    "    \n",
    "    return np.array(img_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_report(y_tru, y_prd, mode, learning_rate, batch_size,epochs, figsize=(7, 7), ax=None):\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    xticks = ['precision', 'recall', 'f1-score', 'support']\n",
    "    yticks = [\"Control\", \"Moderate\", \"Alzheimer's\" ] \n",
    "    yticks += ['avg']\n",
    "\n",
    "    rep = np.array(precision_recall_fscore_support(y_tru, y_prd)).T\n",
    "    avg = np.mean(rep, axis=0)\n",
    "    avg[-1] = np.sum(rep[:, -1])\n",
    "    rep = np.insert(rep, rep.shape[0], avg, axis=0)\n",
    "\n",
    "    sns.heatmap(rep,\n",
    "                annot=True, \n",
    "                cbar=False, \n",
    "                xticklabels=xticks, \n",
    "                yticklabels=yticks,\n",
    "                ax=ax, cmap = \"Blues\")\n",
    "    \n",
    "    plt.savefig('report_' + str(mode) + '_' + str(learning_rate) +'_' + str(batch_size)+'_' + str(epochs)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_confusion_matrix(result, test_label,mode, learning_rate, batch_size, epochs):\n",
    "    result = F.one_hot(result,num_classes=4)\n",
    "    # print(result)\n",
    "\n",
    "    test_label = F.one_hot(test_label,num_classes=4)\n",
    "    # print(test_label)\n",
    "\n",
    "    true_label= np.argmax(test_label, axis =1)\n",
    "\n",
    "    predicted_label= np.argmax(result, axis =1)\n",
    "    \n",
    "    n_classes = 4\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    thres = dict()\n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], thres[i] = precision_recall_curve(test_label[:, i],\n",
    "                                                            result[:, i])\n",
    "\n",
    "\n",
    "    print (\"Classification Report :\") \n",
    "    print (classification_report(true_label, predicted_label))\n",
    "    cr = classification_report(true_label, predicted_label, output_dict=True)\n",
    "    return cr, precision, recall, thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=100, kernel_size=3, stride=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=100, out_channels=50, kernel_size=3, stride=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout2 = nn.Dropout(p=0.3)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(50 * 16 * 16, 4)  # Assuming input shape (72, 72, 1) after convolutions and pooling\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        out=torch.softmax(x, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "# 多尺度卷积块\n",
    "class MultiScaleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MultiScaleConv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=5, padding=2)\n",
    "        self.conv5 = nn.Conv2d(in_channels, out_channels, kernel_size=7, padding=3)\n",
    "        self.bn = nn.BatchNorm2d(out_channels * 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv3(x)\n",
    "        x3 = self.conv5(x)\n",
    "        x = torch.cat((x1, x2, x3), dim=1)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "class new_AttentionMultiScaleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(new_AttentionMultiScaleCNN, self).__init__()\n",
    "        self.multi_scale_conv1 = MultiScaleConv(3, 64)\n",
    "        self.se1 = SELayer(64 * 3)\n",
    "\n",
    "        self.multi_scale_conv2 = MultiScaleConv(64 * 3, 100)\n",
    "        self.se2 = SELayer(100 * 3)\n",
    "\n",
    "        self.multi_scale_conv3 = MultiScaleConv(100 * 3, 50)\n",
    "        self.se3 = SELayer(50 * 3)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc = nn.Linear(50 * 3 * 9 * 9, num_classes) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.multi_scale_conv1(x))\n",
    "        x = self.se1(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.relu(self.multi_scale_conv2(x))\n",
    "        x = self.se2(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.relu(self.multi_scale_conv3(x))\n",
    "        x = self.se3(x)\n",
    "        x = self.maxpool(x)\n",
    "        # print(x.shape)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC(nn.Module):\n",
    "    def __init__(self, in_size, out_size, dropout_r=0., use_relu=True):\n",
    "        super(FC, self).__init__()\n",
    "        self.dropout_r = dropout_r\n",
    "        self.use_relu = use_relu\n",
    "\n",
    "        self.linear = nn.Linear(in_size, out_size)\n",
    "\n",
    "        if use_relu:\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if dropout_r > 0:\n",
    "            self.dropout = nn.Dropout(dropout_r)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "\n",
    "        if self.use_relu:\n",
    "            x = self.relu(x)\n",
    "\n",
    "        if self.dropout_r > 0:\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        return x\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_size, mid_size, out_size, dropout_r=0., use_relu=True):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.fc = FC(in_size, mid_size, dropout_r=dropout_r, use_relu=use_relu)\n",
    "        self.linear = nn.Linear(mid_size, out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(self.fc(x))\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(FFN, self).__init__()\n",
    "\n",
    "        self.mlp = MLP(\n",
    "            in_size=50,\n",
    "            mid_size=100,\n",
    "            out_size=50,\n",
    "            dropout_r=0.5,\n",
    "            use_relu=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mode,batch_size, epochs, learning_rate, seed):\n",
    "    train_img = make_img(\"../../processed_data/PPMI/MRI_nobrain/X_train_img.pkl\")\n",
    "    val_img = make_img(\"../../processed_data/PPMI/overlap/X_val_img.pkl\")\n",
    "    test_img = make_img(\"../../processed_data/PPMI/overlap/X_test_img.pkl\")\n",
    "    print(train_img.shape,test_img.shape)\n",
    "\n",
    "    y_train = pd.read_csv(\"../../processed_data/PPMI/MRI_nobrain/y_train.csv\").drop(\"PATNO Visit\", axis=1).values.astype(\"int\").flatten()\n",
    "    y_val = pd.read_csv(\"../../processed_data/PPMI/overlap/y_val.csv\").drop(\"PATNO Visit\", axis=1).values.astype(\"int\").flatten()\n",
    "    y_test = pd.read_csv(\"../../processed_data/PPMI/overlap/y_test.csv\").drop(\"PATNO Visit\", axis=1).values.astype(\"int\").flatten()\n",
    "\n",
    "    train_img_tensor = torch.tensor(train_img, dtype=torch.float).to(device)\n",
    "    val_img_tensor = torch.tensor(val_img, dtype=torch.float).to(device)\n",
    "    test_img_tensor = torch.tensor(test_img, dtype=torch.float).to(device)\n",
    "\n",
    "\n",
    "    train_label_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    val_label_tensor = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "    test_label_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "    # print(val_img_tensor.shape,val_label_tensor.shape)\n",
    "    \n",
    "    # seeds = random.sample(range(1, 200),1)\n",
    "    # train_img_tensor, val_img_tensor, train_label_tensor, val_label_tensor = train_test_split(X, y, test_size=0.2, random_state=seeds[0])\n",
    "\n",
    "    train_dataset = TensorDataset(train_img_tensor, train_label_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_dataset = TensorDataset(val_img_tensor, val_label_tensor)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_dataset = TensorDataset(test_img_tensor, test_label_tensor)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    class_weights = compute_class_weight('balanced', classes=torch.unique(torch.tensor(y_train)).numpy(), y=y_train)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "    \n",
    "\n",
    "    model=new_AttentionMultiScaleCNN(num_classes=4).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    best_val_acc=0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predicted_label=[]\n",
    "        true_label=[]\n",
    "        for img, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(img)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            predicted_label.extend(predicted.tolist())\n",
    "            true_label.extend(labels.tolist())\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        # train_acc = 100.0 * correct / total\n",
    "        train_acc = f1_score(true_label,predicted_label,average='macro')\n",
    "        # 在验证集上评估模型\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predicted_label=[]\n",
    "        true_label=[]\n",
    "        for img, labels in val_loader:\n",
    "            outputs = model(img)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            predicted_label.extend(predicted.tolist())\n",
    "            true_label.extend(labels.tolist())\n",
    "        # val_acc = 100.0 * correct / total\n",
    "        val_acc = f1_score(true_label,predicted_label,average='macro')\n",
    "        print(f\"Epoch {epoch+1}, train Loss: {train_loss},train acc:{train_acc},val acc:{val_acc},best acc:{best_val_acc}\")\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = model\n",
    "            torch.save(best_model.state_dict(), f'../../models/PPMI/MRI/best_{seed}.pth')\n",
    "            print(f'Epoch {epoch+1} get best modal')\n",
    "    \n",
    "    best_model.eval()\n",
    "    # all_probs=[]\n",
    "    predicted_label=[]\n",
    "    with torch.no_grad():\n",
    "        outputs = best_model(test_img_tensor)\n",
    "        # probs = nn.functional.softmax(outputs, dim=1)\n",
    "        # all_probs.extend(probs.cpu().detach().numpy())\n",
    "        _, predicted = outputs.max(1)\n",
    "        predicted_label.extend(predicted.tolist())\n",
    "    # test_acc = 100.0 * correct / total\n",
    "    test_acc = f1_score(y_test,predicted_label,average='macro')\n",
    "    # 计算AUC\n",
    "    num_classes=4\n",
    "    true_label_binarized = label_binarize(y_test, classes=list(range(num_classes)))\n",
    "    # predicted_label_binarized = label_binarize(predicted_label, classes=list(range(num_classes)))\n",
    "    auc_score = roc_auc_score(true_label_binarized, outputs.cpu().detach().numpy(), average='macro', multi_class='ovr')\n",
    "    \n",
    "    print(f'test Acc: {test_acc:.4f},test auc: {auc_score:.4f}')\n",
    "    print(predicted_label)\n",
    "    cr, precision, recall, thresholds = calc_confusion_matrix(torch.tensor(predicted_label), test_label_tensor.cpu(), mode, learning_rate, batch_size, epochs)\n",
    "    \n",
    "    return cr , batch_size, learning_rate, epochs, seed,auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accurancy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1=[]\n",
    "auc_score_list=[]\n",
    "seeds = random.sample(range(1, 200), 5)\n",
    "for s in seeds:\n",
    "    set_random_seed(s)\n",
    "    print('seeds:',s)\n",
    "    cr, bs_, lr_, e_ , seed,auc_score= train('new_AttentionMultiScaleCNN', 32, 100, 0.00001, s)\n",
    "    accurancy.append(cr['accuracy'])\n",
    "    precision.append(cr[\"macro avg\"][\"precision\"])\n",
    "    recall.append(cr[\"macro avg\"][\"recall\"])\n",
    "    f1.append(cr[\"macro avg\"][\"f1-score\"])\n",
    "    auc_score_list.append(auc_score)\n",
    "    print ('-'*55)\n",
    "print(\"Mean accuracy is: \",sum(accurancy)/len(accurancy))\n",
    "print(\"precision:\",sum(precision)/len(precision))\n",
    "print(\"recall:\",sum(recall)/len(recall))\n",
    "print(\"f1:\",sum(f1)/len(f1))\n",
    "print(\"auc_score:\",sum(auc_score_list)/len(auc_score_list))\n",
    "print(\"Std accuracy: \" + str(np.array(accurancy).std()))\n",
    "print(\"Std precision: \" + str(np.array(precision).std()))\n",
    "print(\"Std recall: \" + str(np.array(recall).std()))\n",
    "print(\"Std f1: \" + str(np.array(f1).std()))\n",
    "print(\"Std auc_score: \" + str(np.array(auc_score_list).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard_scaler = StandardScaler()\n",
    "test_img = make_img(\"../../processed_data/PPMI/overlap/X_test_img.pkl\")\n",
    "# test_img = make_img(\"../../processed_data/PPMI/overlap/X_test_img.pkl\")\n",
    "test_label = pd.read_csv(\"../../processed_data/PPMI/overlap/y_test.csv\").drop(\"PATNO Visit\", axis=1).values.astype(\"int\").flatten()\n",
    "test_img_tensor = torch.tensor(test_img, dtype=torch.float).to(device)\n",
    "# test_img_tensor = torch.tensor(test_img, dtype=torch.float).to(device)\n",
    "modal_list=[22,45,152,174,176]\n",
    "print('f1_score                 acc                 precision           recall              auc             aupr')\n",
    "accurancy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1=[]\n",
    "auc_score_list=[]\n",
    "aupr_score_list=[]\n",
    "for i in modal_list:\n",
    "    img_modal=new_AttentionMultiScaleCNN(num_classes=4).to(device)\n",
    "    img_modal.load_state_dict(torch.load(f'../../models/PPMI/MRI/best_{i}.pth'))\n",
    "    img_modal.eval()\n",
    "    predicted_label_0=[]\n",
    "    with torch.no_grad():\n",
    "        outputs_0 = img_modal(test_img_tensor)\n",
    "        # probs_0 = nn.functional.softmax(outputs_0, dim=1)\n",
    "        # all_probs_0.extend(probs_0.cpu().detach().numpy())\n",
    "        _, predicted_0 = outputs_0.max(1)\n",
    "        predicted_label_0.extend(predicted_0.tolist())\n",
    "\n",
    "    num_classes=4\n",
    "    true_label_binarized = label_binarize(test_label, classes=list(range(num_classes)))\n",
    "    test_acc_0=accuracy_score(test_label,predicted_label_0)\n",
    "    test_f1_0 = f1_score(test_label,predicted_label_0,average='macro')\n",
    "    test_precision_0=precision_score(test_label,predicted_label_0,average='macro')\n",
    "    recall_0=recall_score(test_label,predicted_label_0,average='macro')\n",
    "    auc_score_0 = roc_auc_score(true_label_binarized, outputs_0.cpu().detach().numpy(), average='macro', multi_class='ovr')\n",
    "    aupr_score_0 = average_precision_score(true_label_binarized, outputs_0.cpu().detach().numpy(), average='macro')\n",
    "    print(test_f1_0,test_acc_0,test_precision_0,recall_0,auc_score_0,aupr_score_0)\n",
    "    accurancy.append(test_acc_0)\n",
    "    precision.append(test_precision_0)\n",
    "    recall.append(recall_0)\n",
    "    f1.append(test_f1_0)\n",
    "    auc_score_list.append(auc_score_0)\n",
    "    aupr_score_list.append(aupr_score_0)\n",
    "print('avg')\n",
    "print(sum(f1)/len(modal_list),sum(accurancy)/len(modal_list),sum(precision)/len(modal_list),sum(recall)/len(modal_list),sum(auc_score_list)/len(modal_list),sum(aupr_score_list)/len(modal_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MOGONET",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
