{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset,TensorDataset,SubsetRandomSampler\n",
    "from sklearn.metrics import classification_report\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_recall_curve,f1_score,roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import precision_recall_curve,f1_score,roc_curve,roc_auc_score,auc,accuracy_score,average_precision_score,precision_score,recall_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_img(t_img):\n",
    "    img = pd.read_pickle(t_img)\n",
    "    img_l = []\n",
    "    for i in range(len(img)):\n",
    "        img_l.append(img.values[i][0])\n",
    "    \n",
    "    return np.array(img_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm1d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.LayerNorm):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_report(y_tru, y_prd, mode, learning_rate, batch_size,epochs, figsize=(7, 7), ax=None):\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    xticks = ['precision', 'recall', 'f1-score', 'support']\n",
    "    yticks = [\"Control\", \"Moderate\", \"Alzheimer's\" ] \n",
    "    yticks += ['avg']\n",
    "\n",
    "    rep = np.array(precision_recall_fscore_support(y_tru, y_prd)).T\n",
    "    avg = np.mean(rep, axis=0)\n",
    "    avg[-1] = np.sum(rep[:, -1])\n",
    "    rep = np.insert(rep, rep.shape[0], avg, axis=0)\n",
    "\n",
    "    sns.heatmap(rep,\n",
    "                annot=True, \n",
    "                cbar=False, \n",
    "                xticklabels=xticks, \n",
    "                yticklabels=yticks,\n",
    "                ax=ax, cmap = \"Blues\")\n",
    "    \n",
    "    plt.savefig('report_' + str(mode) + '_' + str(learning_rate) +'_' + str(batch_size)+'_' + str(epochs)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_confusion_matrix(result, test_label,mode, learning_rate, batch_size, epochs):\n",
    "    result = F.one_hot(result,num_classes=4)\n",
    "\n",
    "\n",
    "    test_label = F.one_hot(test_label,num_classes=4)\n",
    "\n",
    "\n",
    "    true_label= np.argmax(test_label, axis =1)\n",
    "\n",
    "    predicted_label= np.argmax(result, axis =1)\n",
    "    \n",
    "    n_classes = 4\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    thres = dict()\n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], thres[i] = precision_recall_curve(test_label[:, i],\n",
    "                                                            result[:, i])\n",
    "\n",
    "\n",
    "    print (\"Classification Report :\") \n",
    "    print (classification_report(true_label, predicted_label))\n",
    "    cr = classification_report(true_label, predicted_label, output_dict=True)\n",
    "    return cr, precision, recall, thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "# 多尺度卷积块\n",
    "class MultiScaleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MultiScaleConv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=5, padding=2)\n",
    "        self.conv5 = nn.Conv2d(in_channels, out_channels, kernel_size=7, padding=3)\n",
    "        self.bn = nn.BatchNorm2d(out_channels * 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv3(x)\n",
    "        x3 = self.conv5(x)\n",
    "        x = torch.cat((x1, x2, x3), dim=1)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "    \n",
    "class new_AttentionMultiScaleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(new_AttentionMultiScaleCNN, self).__init__()\n",
    "        self.multi_scale_conv1 = MultiScaleConv(3, 64)\n",
    "        self.se1 = SELayer(64 * 3)\n",
    "\n",
    "        self.multi_scale_conv2 = MultiScaleConv(64 * 3, 100)\n",
    "        self.se2 = SELayer(100 * 3)\n",
    "\n",
    "        self.multi_scale_conv3 = MultiScaleConv(100 * 3, 50)\n",
    "        self.se3 = SELayer(50 * 3)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc = nn.Linear(50 * 3 * 9 * 9, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.multi_scale_conv1(x))\n",
    "        x = self.se1(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.relu(self.multi_scale_conv2(x))\n",
    "        x = self.se2(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.relu(self.multi_scale_conv3(x))\n",
    "        x = self.se3(x)\n",
    "        x = self.maxpool(x)\n",
    "        # print(x.shape)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self,input,num_classes=4):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, num_classes)\n",
    "        self.dropout1 = nn.Dropout(0.4)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(256)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(128)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC(nn.Module):\n",
    "    def __init__(self, in_size, out_size, dropout_r=0., use_relu=True):\n",
    "        super(FC, self).__init__()\n",
    "        self.dropout_r = dropout_r\n",
    "        self.use_relu = use_relu\n",
    "\n",
    "        self.linear = nn.Linear(in_size, out_size)\n",
    "\n",
    "        if use_relu:\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if dropout_r > 0:\n",
    "            self.dropout = nn.Dropout(dropout_r)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "\n",
    "        if self.use_relu:\n",
    "            x = self.relu(x)\n",
    "\n",
    "        if self.dropout_r > 0:\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim,output_dim, hidden_dims=[100,200,100]):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_dim, hidden_dims[0]))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        for i in range(1, len(hidden_dims)):\n",
    "            layers.append(nn.Linear(hidden_dims[i-1], hidden_dims[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        layers.append(nn.Linear(hidden_dims[-1], output_dim))\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(FFN, self).__init__()\n",
    "\n",
    "        self.mlp = MLP(\n",
    "            input_dim=input_dim,\n",
    "            output_dim=output_dim,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self,in_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=in_dim, num_heads=2)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.layer_norm1 = nn.LayerNorm(in_dim)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.layer_norm2 = nn.LayerNorm(in_dim)\n",
    "        self.ffn=FFN(in_dim,in_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs=torch.unsqueeze(inputs, dim=1)\n",
    "        outputs, _ = self.multihead_attn(inputs, inputs, inputs, attn_mask=None)\n",
    "        outputs = self.dropout1(outputs)\n",
    "        outputs = self.layer_norm1(inputs + outputs)\n",
    "        outputs_2=self.ffn(outputs)\n",
    "        outputs_2 = self.dropout2(outputs_2)\n",
    "        all_outputs=self.layer_norm2(outputs + outputs_2)\n",
    "        return all_outputs[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Cross_modal_transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cross_modal_transformer, self).__init__()\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=50, num_heads=2)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.layer_norm = nn.LayerNorm(50)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.ffn=MLP(50,50,[50,100,50])\n",
    "\n",
    "    def forward(self, x, y,layer_num):\n",
    "        x=torch.unsqueeze(x, dim=1)\n",
    "        y=torch.unsqueeze(y, dim=1)\n",
    "        for i in range(layer_num):\n",
    "            x = self.layer_norm(x)\n",
    "            y = self.layer_norm(y)\n",
    "            att_x = x + self.dropout1(self.multihead_attn(x, y, y, attn_mask=None)[0])\n",
    "            att_y = y + self.dropout1(self.multihead_attn(y, x, x, attn_mask=None)[0])\n",
    "\n",
    "            x = att_x + self.dropout2(self.ffn(self.layer_norm(att_x)))\n",
    "            y = att_y + self.dropout2(self.ffn(self.layer_norm(att_x)))\n",
    "\n",
    "        return x.squeeze(1),y.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_modal_model(nn.Module):\n",
    "    def __init__(self,mode,transcriptomicsinput):\n",
    "        super(multi_modal_model, self).__init__()\n",
    "        self.plasma_modal=NeuralNetwork(transcriptomicsinput,num_classes=50)\n",
    "\n",
    "        self.img_modal=new_AttentionMultiScaleCNN(num_classes=50)\n",
    "\n",
    "        self.NeuralNetwork=NeuralNetwork(transcriptomicsinput,num_classes=4)\n",
    "        self.img=new_AttentionMultiScaleCNN(num_classes=4)\n",
    "    \n",
    "        self.mode=mode\n",
    "\n",
    "        self.fc0 = nn.Linear(100, 4)\n",
    "        self.fc2 = nn.Linear(200,4)\n",
    "        self.fc0.apply(weight_init)\n",
    "        self.fc2.apply(weight_init)\n",
    "\n",
    "        self.transformer=Cross_modal_transformer()\n",
    "        self.transformer.apply(weight_init)\n",
    "\n",
    "        self.mlp1=MLP(100,4,[100,100,50])\n",
    "        self.mlp1.apply(weight_init)\n",
    "\n",
    "        self.mlp2=MLP(200,4,[200,100,50])\n",
    "        self.mlp2.apply(weight_init)\n",
    "\n",
    "    def forward(self, train_plasma, train_img):\n",
    "\n",
    "        dense_plasma=self.plasma_modal(train_plasma)\n",
    "        dense_img=self.img_modal(train_img)\n",
    "        if self.mode == 'None':\n",
    "            merged = torch.cat((dense_plasma,dense_img),axis=1)\n",
    "\n",
    "            output = self.mlp1(merged)\n",
    "        elif self.mode == 'MM_Tansformer':\n",
    "            pp_att,ii_att = self.transformer(dense_plasma,dense_img,layer_num=1)\n",
    "            \n",
    "            merged = torch.cat((pp_att,ii_att),axis=1)\n",
    "            output=self.mlp2(torch.cat((dense_plasma,dense_img,merged),axis=1))\n",
    "        return dense_plasma,dense_img,torch.softmax(output,dim=1),merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_modal_model_MDB(nn.Module):\n",
    "    def __init__(self,mode,transcriptomicsinput):\n",
    "        super(multi_modal_model_MDB, self).__init__()\n",
    "        self.plasma_modal=NeuralNetwork(transcriptomicsinput,num_classes=4)\n",
    "        self.plasma_modal.load_state_dict(torch.load('../../models/PPMI/Transcriptomics/best_146.pth'))\n",
    "        self.plasma_modal.fc4 = nn.Linear(64, 50)\n",
    "\n",
    "        self.img_modal=new_AttentionMultiScaleCNN(num_classes=4)\n",
    "        self.img_modal.load_state_dict(torch.load('../../models/PPMI/MRI/best_22.pth'))\n",
    "        self.img_modal.fc = nn.Linear(50 * 3 * 9 * 9, 50)\n",
    "\n",
    "        self.NeuralNetwork=NeuralNetwork(transcriptomicsinput,num_classes=4)\n",
    "        self.img=new_AttentionMultiScaleCNN(num_classes=4)\n",
    "    \n",
    "        self.mode=mode\n",
    "\n",
    "\n",
    "        self.fc0 = nn.Linear(100, 4)\n",
    "        self.fc2 = nn.Linear(200,4)\n",
    "        self.fc0.apply(weight_init)\n",
    "        self.fc2.apply(weight_init)\n",
    "\n",
    "        self.transformer=Cross_modal_transformer()\n",
    "        self.transformer.apply(weight_init)\n",
    "\n",
    "        self.mlp1=MLP(100,4,[100,100,50])\n",
    "        self.mlp1.apply(weight_init)\n",
    "\n",
    "        self.mlp2=MLP(200,4,[200,100,50])\n",
    "        self.mlp2.apply(weight_init)\n",
    "\n",
    "    def forward(self, train_plasma, train_img):\n",
    "\n",
    "        dense_plasma=self.plasma_modal(train_plasma)\n",
    "        dense_img=self.img_modal(train_img)\n",
    "        if self.mode == 'None':\n",
    "            merged = torch.cat((dense_plasma,dense_img),axis=1)\n",
    "            output = self.mlp1(merged)\n",
    "            \n",
    "        elif self.mode == 'MM_Tansformer':\n",
    "            pp_att,ii_att = self.transformer(dense_plasma,dense_img,layer_num=5)\n",
    "            \n",
    "            merged = torch.cat((pp_att,ii_att),axis=1)\n",
    "            output=self.mlp2(torch.cat((dense_plasma,dense_img,merged),axis=1))\n",
    "        return dense_plasma,dense_img,torch.softmax(output,dim=1),merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mode,MDB, batch_size, epochs, learning_rate, seed,a_alpha):\n",
    "    alpha=a_alpha\n",
    "\n",
    "    train_transcriptomics = pd.read_csv(\"../../processed_data/PPMI/overlap/X_train_transpot.csv\").drop(\"PATNO Visit\", axis=1).values\n",
    "    val_transcriptomics = pd.read_csv(\"../../processed_data/PPMI/overlap/X_val_transpot.csv\").drop(\"PATNO Visit\", axis=1).values\n",
    "    test_transcriptomics = pd.read_csv(\"../../processed_data/PPMI/overlap/X_test_transpot.csv\").drop(\"PATNO Visit\", axis=1).values\n",
    "    \n",
    "    train_img = make_img(\"../../processed_data/PPMI/overlap/X_train_img.pkl\")\n",
    "    val_img = make_img(\"../../processed_data/PPMI/overlap/X_val_img.pkl\")\n",
    "    test_img = make_img(\"../../processed_data/PPMI/overlap/X_test_img.pkl\")\n",
    "    train_label = pd.read_csv(\"../../processed_data/PPMI/overlap/y_train.csv\").drop(\"PATNO Visit\", axis=1).values.astype(\"int\").flatten()\n",
    "    val_label = pd.read_csv(\"../../processed_data/PPMI/overlap/y_val.csv\").drop(\"PATNO Visit\", axis=1).values.astype(\"int\").flatten()\n",
    "    test_label = pd.read_csv(\"../../processed_data/PPMI/overlap/y_test.csv\").drop(\"PATNO Visit\", axis=1).values.astype(\"int\").flatten()\n",
    "\n",
    "    train_transcriptomics_tensor = torch.tensor(train_transcriptomics, dtype=torch.float).to(device)\n",
    "    val_transcriptomics_tensor = torch.tensor(val_transcriptomics, dtype=torch.float).to(device)\n",
    "    test_transcriptomics_tensor = torch.tensor(test_transcriptomics, dtype=torch.float).to(device)\n",
    "\n",
    "    train_img_tensor = torch.tensor(train_img, dtype=torch.float).to(device)\n",
    "    val_img_tensor = torch.tensor(val_img, dtype=torch.float).to(device)\n",
    "    test_img_tensor = torch.tensor(test_img, dtype=torch.float).to(device)\n",
    "\n",
    "    train_label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n",
    "    val_label_tensor = torch.tensor(val_label, dtype=torch.long).to(device)\n",
    "    test_label_tensor = torch.tensor(test_label, dtype=torch.long).to(device)\n",
    "\n",
    "    train_dataset = TensorDataset(train_transcriptomics_tensor,train_img_tensor, train_label_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_dataset = TensorDataset(val_transcriptomics_tensor,val_img_tensor, val_label_tensor)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_dataset = TensorDataset(test_transcriptomics_tensor,test_img_tensor, test_label_tensor)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "    class_weights = compute_class_weight('balanced', classes=torch.unique(torch.tensor(train_label)).numpy(), y=train_label)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "    # print(class_weights)\n",
    "\n",
    "    # Initialize model\n",
    "    if MDB:\n",
    "        print('MDB')\n",
    "        model = multi_modal_model_MDB(mode,train_transcriptomics.shape[1]).to(device)\n",
    "    else:\n",
    "        model = multi_modal_model(mode,train_transcriptomics.shape[1]).to(device)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    best_val_acc=0\n",
    "    ratio_list=[]\n",
    "    for epoch in range(epochs):\n",
    "        ratio_epoch=[]\n",
    "        # set_random_seed(epoch)\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        relu = nn.ReLU(inplace=True)\n",
    "        tanh = nn.Tanh()\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predicted_label=[]\n",
    "        true_label=[]\n",
    "        for transpot,img, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            dense_transpot,dense_img,outputs,_ = model(transpot,img)\n",
    "\n",
    "            if mode=='None':\n",
    "                weight_size = model.fc0.weight.size(1)\n",
    "                out_transpot = (torch.mm(dense_transpot, torch.transpose(model.fc0.weight[:, :weight_size // 2], 0, 1))\n",
    "                        + model.fc0.bias / 2)\n",
    "                out_img = (torch.mm(dense_img, torch.transpose(model.fc0.weight[:, weight_size // 2:], 0, 1))\n",
    "                        + model.fc0.bias / 2)\n",
    "            else:\n",
    "                weight_size = model.fc2.weight.size(1)\n",
    "                out_transpot = (torch.mm(dense_transpot, torch.transpose(model.fc2.weight[:, :weight_size // 4], 0, 1))\n",
    "                        + model.fc2.bias / 2)\n",
    "                out_img = (torch.mm(dense_img, torch.transpose(model.fc2.weight[:, weight_size // 4:weight_size // 2], 0, 1))\n",
    "                        + model.fc2.bias / 2)\n",
    "            _, predicted_T = out_transpot.max(1)\n",
    "            _, predicted_M = out_img.max(1)\n",
    "            score_transcriptomics = torch.tensor(f1_score(labels.tolist(),predicted_T.tolist(),average='macro'))\n",
    "            score_img = torch.tensor(f1_score(labels.tolist(),predicted_M.tolist(),average='macro'))\n",
    "\n",
    "            \n",
    "            \n",
    "            ratio_transpot = score_transcriptomics / score_img\n",
    "            ratio_img = 1/ratio_transpot\n",
    "            loss_transcriptomics = criterion(out_transpot, labels)\n",
    "            loss_img = criterion(out_img, labels)\n",
    "\n",
    "            ratio_epoch.append(ratio_img.cpu().detach().numpy())\n",
    "\n",
    "            if MDB:\n",
    "                if ratio_transpot > 1:\n",
    "                    beta = 0  # audio coef\n",
    "                    lam = tanh(alpha *relu(ratio_transpot))  # visual coef\n",
    "                elif ratio_transpot < 1:\n",
    "                    beta = tanh(alpha *relu(ratio_img))\n",
    "                    lam = 0\n",
    "                else:\n",
    "                    beta = 0\n",
    "                    lam = 0\n",
    "                loss = criterion(outputs, labels) + beta * loss_transcriptomics + lam * loss_img\n",
    "                loss.backward()\n",
    "            else:\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "        \n",
    "\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            # correct += predicted.eq(labels).sum().item()\n",
    "            predicted_label.extend(predicted.tolist())\n",
    "\n",
    "            true_label.extend(labels.tolist())\n",
    "        # print(sum(ratio_epoch)/len(ratio_epoch))\n",
    "        ratio_list.append(sum(ratio_epoch)/len(ratio_epoch))\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        # train_acc = 100.0 * correct / total\n",
    "        train_acc = f1_score(true_label,predicted_label,average='macro')\n",
    "        \n",
    "        # 在验证集上评估模型\n",
    "        model.eval()\n",
    "        predicted_label=[]\n",
    "        # true_label=[]\n",
    "        with torch.no_grad():\n",
    "            _,_,outputs,_ = model(val_transcriptomics_tensor,val_img_tensor)\n",
    "            # probs = nn.functional.softmax(outputs, dim=1)\n",
    "            # all_probs.extend(probs.cpu().detach().numpy())\n",
    "            _, predicted = outputs.max(1)\n",
    "            predicted_label.extend(predicted.tolist())\n",
    "        # val_acc = 100.0 * correct / total\n",
    "        val_acc = f1_score(val_label,predicted_label,average='macro')\n",
    "        predicted_label=[]\n",
    "        with torch.no_grad():\n",
    "            _,_,outputs,_ = model(test_transcriptomics_tensor,test_img_tensor)\n",
    "            # probs = nn.functional.softmax(outputs, dim=1)\n",
    "            # all_probs.extend(probs.cpu().detach().numpy())\n",
    "            _, predicted = outputs.max(1)\n",
    "            predicted_label.extend(predicted.tolist())\n",
    "        # test_acc = 100.0 * correct / total\n",
    "        test_acc = f1_score(test_label,predicted_label,average='macro')\n",
    "        print(f\"Epoch {epoch+1}, train Loss: {train_loss},train acc:{train_acc},val acc:{val_acc},best acc:{best_val_acc},test acc:{test_acc},ρ:{sum(ratio_epoch)/len(ratio_epoch)}\")\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = model\n",
    "            if MDB:\n",
    "                torch.save(best_model.state_dict(), f'../../models/PPMI/Multi-modal/{mode}_MDB_{alpha}_best_{seed}.pth')\n",
    "            else:\n",
    "                torch.save(best_model.state_dict(), f'../../models/PPMI/Multi-modal/{mode}_best_{seed}.pth')\n",
    "            print(f'Epoch {epoch+1} get best modal')\n",
    "    \n",
    "        \n",
    "    if MDB:\n",
    "        test_model=multi_modal_model_MDB(mode,train_transcriptomics.shape[1]).to(device)\n",
    "        test_model.load_state_dict(torch.load(f'../../models/PPMI/Multi-modal/{mode}_MDB_{alpha}_best_{seed}.pth'))\n",
    "    else:\n",
    "        test_model=multi_modal_model(mode,train_transcriptomics.shape[1]).to(device)\n",
    "        test_model.load_state_dict(torch.load(f'../../models/PPMI/Multi-modal/{mode}_best_{seed}.pth'))\n",
    "    test_model.eval()\n",
    "    # all_probs=[]\n",
    "    predicted_label=[]\n",
    "    with torch.no_grad():\n",
    "        _,_,outputs,_ = test_model(test_transcriptomics_tensor,test_img_tensor)\n",
    "        # probs = nn.functional.softmax(outputs, dim=1)\n",
    "        # all_probs.extend(probs.cpu().detach().numpy())\n",
    "        _, predicted = outputs.max(1)\n",
    "        predicted_label.extend(predicted.tolist())\n",
    "    # test_acc = 100.0 * correct / total\n",
    "    test_acc = f1_score(test_label,predicted_label,average='macro')\n",
    "    # 计算AUC\n",
    "    num_classes=4\n",
    "    true_label_binarized = label_binarize(test_label, classes=list(range(num_classes)))\n",
    "    # predicted_label_binarized = label_binarize(predicted_label, classes=list(range(num_classes)))\n",
    "    auc_score = roc_auc_score(true_label_binarized, outputs.cpu().detach().numpy(), average='macro', multi_class='ovr')\n",
    "\n",
    "    \n",
    "    print(f'test Acc: {test_acc:.4f},test auc: {auc_score:.4f}')\n",
    "    print(predicted_label)\n",
    "\n",
    "    cr, precision, recall, thresholds = calc_confusion_matrix(torch.tensor(predicted_label), test_label_tensor.cpu(), mode, learning_rate, batch_size, epochs)\n",
    "    # model.apply(weight_init)\n",
    "    return cr , batch_size, learning_rate, epochs, seed ,auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeding=50\n",
    "accurancy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1=[]\n",
    "auc_score_list=[]\n",
    "for s in range(5):\n",
    "    set_random_seed(s)\n",
    "    print('seeds:',s)\n",
    "    cr, bs_, lr_, e_ , seed,auc_score= train('None',False, 32, 250, 0.00001, s,0)\n",
    "    accurancy.append(cr['accuracy'])\n",
    "    precision.append(cr[\"macro avg\"][\"precision\"])\n",
    "    recall.append(cr[\"macro avg\"][\"recall\"])\n",
    "    f1.append(cr[\"macro avg\"][\"f1-score\"])\n",
    "    auc_score_list.append(auc_score)\n",
    "    print ('-'*55)\n",
    "print(\"Mean accuracy is: \",sum(accurancy)/len(accurancy))\n",
    "print(\"precision:\",sum(precision)/len(precision))\n",
    "print(\"recall:\",sum(recall)/len(recall))\n",
    "print(\"f1:\",sum(f1)/len(f1))\n",
    "print(\"auc_score:\",sum(auc_score_list)/len(auc_score_list))\n",
    "print(\"Std accuracy: \" + str(np.array(accurancy).std()))\n",
    "print(\"Std precision: \" + str(np.array(precision).std()))\n",
    "print(\"Std recall: \" + str(np.array(recall).std()))\n",
    "print(\"Std f1: \" + str(np.array(f1).std()))\n",
    "print(\"Std auc_score: \" + str(np.array(auc_score_list).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transcriptomics = pd.read_csv(\"../../processed_data/PPMI/overlap/X_test_transpot.csv\").drop(\"PATNO Visit\", axis=1).values\n",
    "test_img = make_img(\"../../processed_data/PPMI/overlap/X_test_img.pkl\")\n",
    "test_label = pd.read_csv(\"../../processed_data/PPMI/overlap/y_test.csv\").drop(\"PATNO Visit\", axis=1).values.astype(\"int\").flatten()\n",
    "test_transcriptomics_tensor = torch.tensor(test_transcriptomics, dtype=torch.float).to(device)\n",
    "test_img_tensor = torch.tensor(test_img, dtype=torch.float).to(device)\n",
    "print('f1_score                 acc                 precision           recall              auc             aupr')\n",
    "accurancy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1=[]\n",
    "auc_score_list=[]\n",
    "aupr_score_list=[]\n",
    "for i in range(5):\n",
    "    multi_modal=multi_modal_model('None',test_transcriptomics.shape[1]).to(device)\n",
    "    multi_modal.load_state_dict(torch.load(f'../../models/PPMI/Multi-modal/None_best_{i}.pth'))\n",
    "    multi_modal.eval()\n",
    "    predicted_label_0=[]\n",
    "    with torch.no_grad():\n",
    "        _,_,outputs_0,_ = multi_modal(test_transcriptomics_tensor,test_img_tensor)\n",
    "        # probs_0 = nn.functional.softmax(outputs_0, dim=1)\n",
    "        # all_probs_0.extend(probs_0.cpu().detach().numpy())\n",
    "        _, predicted_0 = outputs_0.max(1)\n",
    "        predicted_label_0.extend(predicted_0.tolist())\n",
    "\n",
    "    num_classes=4\n",
    "    true_label_binarized = label_binarize(test_label, classes=list(range(num_classes)))\n",
    "    test_acc_0=accuracy_score(test_label,predicted_label_0)\n",
    "    test_f1_0 = f1_score(test_label,predicted_label_0,average='macro')\n",
    "    test_precision_0=precision_score(test_label,predicted_label_0,average='macro')\n",
    "    recall_0=recall_score(test_label,predicted_label_0,average='macro')\n",
    "    auc_score_0 = roc_auc_score(true_label_binarized, outputs_0.cpu().detach().numpy(), average='macro', multi_class='ovr')\n",
    "    aupr_score_0 = average_precision_score(true_label_binarized, outputs_0.cpu().detach().numpy(), average='macro')\n",
    "    print(test_f1_0,test_acc_0,test_precision_0,recall_0,auc_score_0,aupr_score_0)\n",
    "    accurancy.append(test_acc_0)\n",
    "    precision.append(test_precision_0)\n",
    "    recall.append(recall_0)\n",
    "    f1.append(test_f1_0)\n",
    "    auc_score_list.append(auc_score_0)\n",
    "    aupr_score_list.append(aupr_score_0)\n",
    "print('avg')\n",
    "print(sum(f1)/5,sum(accurancy)/5,sum(precision)/5,sum(recall)/5,sum(auc_score_list)/5,sum(aupr_score_list)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMC fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accurancy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1=[]\n",
    "auc_score_list=[]\n",
    "# seeds = random.sample(range(1, 200), 5)\n",
    "for s in range(5):\n",
    "    set_random_seed(s)\n",
    "    print('seeds:',s)\n",
    "    cr, bs_, lr_, e_ , seed,auc_score= train('MM_Tansformer',False, 32, 250, 0.00001, s,0)\n",
    "    accurancy.append(cr['accuracy'])\n",
    "    precision.append(cr[\"macro avg\"][\"precision\"])\n",
    "    recall.append(cr[\"macro avg\"][\"recall\"])\n",
    "    f1.append(cr[\"macro avg\"][\"f1-score\"])\n",
    "    auc_score_list.append(auc_score)\n",
    "    print ('-'*55)\n",
    "print(\"Mean accuracy is: \",sum(accurancy)/len(accurancy))\n",
    "print(\"precision:\",sum(precision)/len(precision))\n",
    "print(\"recall:\",sum(recall)/len(recall))\n",
    "print(\"f1:\",sum(f1)/len(f1))\n",
    "print(\"auc_score:\",sum(auc_score_list)/len(auc_score_list))\n",
    "print(\"Std accuracy: \" + str(np.array(accurancy).std()))\n",
    "print(\"Std precision: \" + str(np.array(precision).std()))\n",
    "print(\"Std recall: \" + str(np.array(recall).std()))\n",
    "print(\"Std f1: \" + str(np.array(f1).std()))\n",
    "print(\"Std auc_score: \" + str(np.array(auc_score_list).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_transcriptomics = pd.read_csv(\"../../processed_data/PPMI/overlap/X_test_transpot.csv\").drop(\"PATNO Visit\", axis=1).values\n",
    "test_img = make_img(\"../../processed_data/PPMI/overlap/X_test_img.pkl\")\n",
    "test_label = pd.read_csv(\"../../processed_data/PPMI/overlap/y_test.csv\").drop(\"PATNO Visit\", axis=1).values.astype(\"int\").flatten()\n",
    "test_transcriptomics_tensor = torch.tensor(test_transcriptomics, dtype=torch.float).to(device)\n",
    "test_img_tensor = torch.tensor(test_img, dtype=torch.float).to(device)\n",
    "\n",
    "print('f1_score                 acc                 precision           recall              auc             aupr')\n",
    "accurancy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1=[]\n",
    "auc_score_list=[]\n",
    "aupr_score_list=[]\n",
    "for i in range(5):\n",
    "    multi_modal=multi_modal_model('MM_Tansformer',test_transcriptomics.shape[1]).to(device)\n",
    "    multi_modal.load_state_dict(torch.load(f'../../models/PPMI/Multi-modal/MM_Tansformer_best_{i}.pth'))\n",
    "    multi_modal.eval()\n",
    "    predicted_label_0=[]\n",
    "    with torch.no_grad():\n",
    "        _,_,outputs_0,_ = multi_modal(test_transcriptomics_tensor,test_img_tensor)\n",
    "        # probs_0 = nn.functional.softmax(outputs_0, dim=1)\n",
    "        # all_probs_0.extend(probs_0.cpu().detach().numpy())\n",
    "        _, predicted_0 = outputs_0.max(1)\n",
    "        predicted_label_0.extend(predicted_0.tolist())\n",
    "\n",
    "    num_classes=4\n",
    "    true_label_binarized = label_binarize(test_label, classes=list(range(num_classes)))\n",
    "    test_acc_0=accuracy_score(test_label,predicted_label_0)\n",
    "    test_f1_0 = f1_score(test_label,predicted_label_0,average='macro')\n",
    "    test_precision_0=precision_score(test_label,predicted_label_0,average='macro')\n",
    "    recall_0=recall_score(test_label,predicted_label_0,average='macro')\n",
    "    auc_score_0 = roc_auc_score(true_label_binarized, outputs_0.cpu().detach().numpy(), average='macro', multi_class='ovr')\n",
    "    aupr_score_0 = average_precision_score(true_label_binarized, outputs_0.cpu().detach().numpy(), average='macro')\n",
    "    print(test_f1_0,test_acc_0,test_precision_0,recall_0,auc_score_0,aupr_score_0)\n",
    "    accurancy.append(test_acc_0)\n",
    "    precision.append(test_precision_0)\n",
    "    recall.append(recall_0)\n",
    "    f1.append(test_f1_0)\n",
    "    auc_score_list.append(auc_score_0)\n",
    "    aupr_score_list.append(aupr_score_0)\n",
    "print('avg')\n",
    "print(sum(f1)/5,sum(accurancy)/5,sum(precision)/5,sum(recall)/5,sum(auc_score_list)/5,sum(aupr_score_list)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeding=50\n",
    "accurancy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1=[]\n",
    "auc_score_list=[]\n",
    "# seeds = random.sample(range(1, 200), 5)\n",
    "for s in range(5):\n",
    "    set_random_seed(s)\n",
    "    print('seeds:',s)\n",
    "    cr, bs_, lr_, e_ , seed,auc_score= train('None',True, 32, 250, 0.00001, s,0.2)\n",
    "    accurancy.append(cr['accuracy'])\n",
    "    precision.append(cr[\"macro avg\"][\"precision\"])\n",
    "    recall.append(cr[\"macro avg\"][\"recall\"])\n",
    "    f1.append(cr[\"macro avg\"][\"f1-score\"])\n",
    "    auc_score_list.append(auc_score)\n",
    "    print ('-'*55)\n",
    "print(\"Mean accuracy is: \",sum(accurancy)/len(accurancy))\n",
    "print(\"precision:\",sum(precision)/len(precision))\n",
    "print(\"recall:\",sum(recall)/len(recall))\n",
    "print(\"f1:\",sum(f1)/len(f1))\n",
    "print(\"auc_score:\",sum(auc_score_list)/len(auc_score_list))\n",
    "print(\"Std accuracy: \" + str(np.array(accurancy).std()))\n",
    "print(\"Std precision: \" + str(np.array(precision).std()))\n",
    "print(\"Std recall: \" + str(np.array(recall).std()))\n",
    "print(\"Std f1: \" + str(np.array(f1).std()))\n",
    "print(\"Std auc_score: \" + str(np.array(auc_score_list).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transcriptomics = pd.read_csv(\"../../processed_data/PPMI/overlap/X_test_transpot.csv\").drop(\"PATNO Visit\", axis=1).values\n",
    "test_img = make_img(\"../../processed_data/PPMI/overlap/X_test_img.pkl\")\n",
    "test_label = pd.read_csv(\"../../processed_data/PPMI/overlap/y_test.csv\").drop(\"PATNO Visit\", axis=1).values.astype(\"int\").flatten()\n",
    "test_transcriptomics_tensor = torch.tensor(test_transcriptomics, dtype=torch.float).to(device)\n",
    "test_img_tensor = torch.tensor(test_img, dtype=torch.float).to(device)\n",
    "print('f1_score                 acc                 precision           recall              auc             aupr')\n",
    "accurancy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1=[]\n",
    "auc_score_list=[]\n",
    "aupr_score_list=[]\n",
    "for i in range(5):\n",
    "    multi_modal=multi_modal_model_MDB('None',test_transcriptomics.shape[1]).to(device)\n",
    "    multi_modal.load_state_dict(torch.load(f'../../models/PPMI/Multi-modal/None_MDB_0.2_best_{i}.pth'))\n",
    "    multi_modal.eval()\n",
    "    predicted_label_0=[]\n",
    "    with torch.no_grad():\n",
    "        _,_,outputs_0,_ = multi_modal(test_transcriptomics_tensor,test_img_tensor)\n",
    "        # probs_0 = nn.functional.softmax(outputs_0, dim=1)\n",
    "        # all_probs_0.extend(probs_0.cpu().detach().numpy())\n",
    "        _, predicted_0 = outputs_0.max(1)\n",
    "        predicted_label_0.extend(predicted_0.tolist())\n",
    "\n",
    "    num_classes=4\n",
    "    true_label_binarized = label_binarize(test_label, classes=list(range(num_classes)))\n",
    "    test_acc_0=accuracy_score(test_label,predicted_label_0)\n",
    "    test_f1_0 = f1_score(test_label,predicted_label_0,average='macro')\n",
    "    test_precision_0=precision_score(test_label,predicted_label_0,average='macro')\n",
    "    recall_0=recall_score(test_label,predicted_label_0,average='macro')\n",
    "    auc_score_0 = roc_auc_score(true_label_binarized, outputs_0.cpu().detach().numpy(), average='macro', multi_class='ovr')\n",
    "    aupr_score_0 = average_precision_score(true_label_binarized, outputs_0.cpu().detach().numpy(), average='macro')\n",
    "    print(test_f1_0,test_acc_0,test_precision_0,recall_0,auc_score_0,aupr_score_0)\n",
    "    accurancy.append(test_acc_0)\n",
    "    precision.append(test_precision_0)\n",
    "    recall.append(recall_0)\n",
    "    f1.append(test_f1_0)\n",
    "    auc_score_list.append(auc_score_0)\n",
    "    aupr_score_list.append(aupr_score_0)\n",
    "print('avg')\n",
    "print(sum(f1)/5,sum(accurancy)/5,sum(precision)/5,sum(recall)/5,sum(auc_score_list)/5,sum(aupr_score_list)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMC fusion+MDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accurancy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1=[]\n",
    "auc_score_list=[]\n",
    "for s in range(5):\n",
    "    set_random_seed(s)\n",
    "    print('seeds:',s)\n",
    "    cr, bs_, lr_, e_ , seed,auc_score= train('MM_Tansformer',True, 32, 250, 0.00001, s,0.2)\n",
    "    accurancy.append(cr['accuracy'])\n",
    "    precision.append(cr[\"macro avg\"][\"precision\"])\n",
    "    recall.append(cr[\"macro avg\"][\"recall\"])\n",
    "    f1.append(cr[\"macro avg\"][\"f1-score\"])\n",
    "    auc_score_list.append(auc_score)\n",
    "    print ('-'*55)\n",
    "print(\"Mean accuracy is: \",sum(accurancy)/len(accurancy))\n",
    "print(\"precision:\",sum(precision)/len(precision))\n",
    "print(\"recall:\",sum(recall)/len(recall))\n",
    "print(\"f1:\",sum(f1)/len(f1))\n",
    "print(\"auc_score:\",sum(auc_score_list)/len(auc_score_list))\n",
    "print(\"Std accuracy: \" + str(np.array(accurancy).std()))\n",
    "print(\"Std precision: \" + str(np.array(precision).std()))\n",
    "print(\"Std recall: \" + str(np.array(recall).std()))\n",
    "print(\"Std f1: \" + str(np.array(f1).std()))\n",
    "print(\"Std auc_score: \" + str(np.array(auc_score_list).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_transcriptomics = pd.read_csv(\"../../processed_data/PPMI/overlap/X_test_transpot.csv\").drop(\"PATNO Visit\", axis=1).values\n",
    "test_img = make_img(\"../../processed_data/PPMI/overlap/X_test_img.pkl\")\n",
    "test_label = pd.read_csv(\"../../processed_data/PPMI/overlap/y_test.csv\").drop(\"PATNO Visit\", axis=1).values.astype(\"int\").flatten()\n",
    "test_transcriptomics_tensor = torch.tensor(test_transcriptomics, dtype=torch.float).to(device)\n",
    "test_img_tensor = torch.tensor(test_img, dtype=torch.float).to(device)\n",
    "print('f1_score                 acc                 precision           recall              auc             aupr')\n",
    "accurancy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1=[]\n",
    "auc_score_list=[]\n",
    "aupr_score_list=[]\n",
    "for i in range(5):\n",
    "    multi_modal=multi_modal_model_MDB('MM_Tansformer',test_transcriptomics.shape[1]).to(device)\n",
    "    multi_modal.load_state_dict(torch.load(f'../../models/PPMI/Multi-modal/MM_Tansformer_MDB_0.2_best_{i}.pth'))\n",
    "    multi_modal.eval()\n",
    "    predicted_label_0=[]\n",
    "    with torch.no_grad():\n",
    "        _,_,outputs_0,_ = multi_modal(test_transcriptomics_tensor,test_img_tensor)\n",
    "        # probs_0 = nn.functional.softmax(outputs_0, dim=1)\n",
    "        # all_probs_0.extend(probs_0.cpu().detach().numpy())\n",
    "        _, predicted_0 = outputs_0.max(1)\n",
    "        predicted_label_0.extend(predicted_0.tolist())\n",
    "\n",
    "    num_classes=4\n",
    "    true_label_binarized = label_binarize(test_label, classes=list(range(num_classes)))\n",
    "    test_acc_0=accuracy_score(test_label,predicted_label_0)\n",
    "    test_f1_0 = f1_score(test_label,predicted_label_0,average='macro')\n",
    "    test_precision_0=precision_score(test_label,predicted_label_0,average='macro')\n",
    "    recall_0=recall_score(test_label,predicted_label_0,average='macro')\n",
    "    auc_score_0 = roc_auc_score(true_label_binarized, outputs_0.cpu().detach().numpy(), average='macro', multi_class='ovr')\n",
    "    aupr_score_0 = average_precision_score(true_label_binarized, outputs_0.cpu().detach().numpy(), average='macro')\n",
    "    print(test_f1_0,test_acc_0,test_precision_0,recall_0,auc_score_0,aupr_score_0)\n",
    "    accurancy.append(test_acc_0)\n",
    "    precision.append(test_precision_0)\n",
    "    recall.append(recall_0)\n",
    "    f1.append(test_f1_0)\n",
    "    auc_score_list.append(auc_score_0)\n",
    "    aupr_score_list.append(aupr_score_0)\n",
    "print('avg')\n",
    "print(sum(f1)/5,sum(accurancy)/5,sum(precision)/5,sum(recall)/5,sum(auc_score_list)/5,sum(aupr_score_list)/5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
